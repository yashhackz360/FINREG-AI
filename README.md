
# FinReg AI: Real-Time Indian Fintech Regulatory Assistant

<div align="center">

<a href="https://www.docker.com/"><img src="https://img.shields.io/badge/Docker-ready-blue?logo=docker"></a>
<a href="https://www.python.org/"><img src="https://img.shields.io/badge/Python-3.9+-green?logo=python"></a>
<a href="https://kafka.apache.org/"><img src="https://img.shields.io/badge/Apache%20Kafka-streaming-black?logo=apachekafka"></a>
<a href="https://www.pinecone.io/"><img src="https://img.shields.io/badge/Pinecone-Vector%20DB-orange"></a>
<a href="https://groq.com/"><img src="https://img.shields.io/badge/Groq-LLM%20Inference-red"></a>
<a href="https://streamlit.io/"><img src="https://img.shields.io/badge/Streamlit-UI%20Framework-FF4B4B?logo=streamlit"></a>

</div>

![ui_Screenshot(finreg_ai _final.png)


FinReg AI is a production-grade Retrieval-Augmented Generation (RAG) system designed to deliver **accurate, real-time answers on Indian financial regulations**.  
It continuously ingests official publications from the **Reserve Bank of India (RBI)** and the **Securities and Exchange Board of India (SEBI)**, builds an evolving knowledge base, and provides **source-backed answers** via a conversational interface.

---

## âœ¨ Key Features
- **Real-Time Data Ingestion**: Monitors RBI and SEBI RSS feeds for new publications.  
- **Event-Driven Architecture**: Built on Apache Kafka with a multi-stage pipeline to decouple discovery, indexing, and summarization.  
- **Automated Regulatory Summaries**: A dedicated microservice generates concise, AI-powered summaries of the latest documents.  
- **Hybrid Search**: BM25 keyword search + semantic vector search with Reciprocal Rank Fusion (RRF).  
- **Vector Database**: Pinecone stores embeddings for scalable semantic retrieval.  
- **Low-Latency LLM**: Groq API provides high-speed inference for responses.  
- **Conversational UI**: Streamlit app supports chat history and displays linked sources.  
- **Containerized Deployment**: Docker Compose orchestrates all services.

---

## ğŸ›ï¸ Architecture

```

Regulatory Feeds (RBI, SEBI)
â”‚
â””â”€> (1) Regulatory Monitor (Producer)
â”‚
â””â”€> Kafka Topic: "regulatory-updates"
â”‚
â””â”€> (2) Real-Time Processor (Consumer/Producer)
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      â”‚
â–¼                      â–¼
Pinecone (Vectors) &     Kafka Topic: "processed-documents"
BM25 Index (Keywords)          â”‚
â””â”€> (3) Summarizer Service (Consumer)
â”‚
â–¼
artifacts/latest_summaries.json
â”‚
â”‚ (Reads Summaries)
â”‚ (Sends Queries)
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â””â”€> (4) Streamlit UI <=> RAG Pipeline <=> Groq LLM API

````

**Data Flow**  
1. **Discover**: `Regulatory Monitor` polls RSS feeds.  
2. **Event 1**: Publishes new docs to `regulatory-updates`.  
3. **Consume & Process**: `Real-Time Processor` fetches, cleans, and chunks documents.  
4. **Index**: Upserts chunks into Pinecone + BM25.  
5. **Event 2**: Publishes cleaned docs to `processed-documents`.  
6. **Summarize**: `Summarizer Service` creates summaries, saves JSON.  
7. **Query**: RAG pipeline fuses vector + keyword results.  
8. **Answer**: Groq LLM generates context-backed responses.

---

## ğŸš€ Setup

### Prerequisites
- Docker + Docker Compose  
- Python 3.9+  
- API keys: Pinecone, Groq  

### Installation

1. **Clone Repo**
   ```bash
   git clone https://github.com/your-username/RAG-FINTECH-REGULATOR.git
   cd RAG-FINTECH-REGULATOR


2. **Environment Variables**

   ```bash
   cp .env.example .env
   ```

   Add your API keys:

   ```env
   PINECONE_API_KEY="YOUR_PINECONE_API_KEY"
   PINECONE_INDEX_NAME="fintech-regulatory-rag"
   GROQ_API_KEY="YOUR_GROQ_API_KEY"
   ```

3. **Streamlit Secrets**

   ```bash
   cp .streamlit/secrets.toml.example .streamlit/secrets.toml
   ```

   Add the same keys in `secrets.toml`.

4. **Clean Setup**

   ```bash
   docker compose down --volumes
   rm -f artifacts/*.pkl artifacts/*.json
   ```

5. **Build & Launch**

   ```bash
   docker compose up --build
   ```

6. **Access**

   * Chat UI: [http://localhost:8501](http://localhost:8501)
   * Kafka Monitor (AKHQ): [http://localhost:8080](http://localhost:8080)

---

## ğŸ“‚ Project Structure

```
RAG-FINTECH-REGULATOR/
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml                  # Streamlit secrets
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_ui.py               # Stage 4 â€“ UI
â”œâ”€â”€ artifacts/                        # State, indexes, summaries
â”œâ”€â”€ data_ingestion/
â”‚   â”œâ”€â”€ kafka_producer.py             # Stage 1 â€“ Producer
â”‚   â””â”€â”€ regulatory_monitor.py         # Stage 1 â€“ Discover
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_ingest_data.py             # Stage 1 â€“ Entrypoint
â”‚   â”œâ”€â”€ 02_realtime_ingestion.py      # Stage 2 â€“ Process/Index
â”‚   â””â”€â”€ 03_summarizer.py              # Stage 3 â€“ Summarize
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                     # Global configs
â”‚   â”œâ”€â”€ generation/llm_generator.py   # Stage 8 â€“ Answer
â”‚   â”œâ”€â”€ pipeline/rag_pipeline.py      # Stage 7 â€“ Query Fusion
â”‚   â”œâ”€â”€ processing/document_processor.py # Stage 2 â€“ Cleaning & chunking
â”‚   â””â”€â”€ retrieval/
â”‚       â”œâ”€â”€ embedder.py               # Stage 4 â€“ Embedding
â”‚       â”œâ”€â”€ keyword_index.py          # Stage 4 â€“ BM25 Index
â”‚       â””â”€â”€ vector_index.py           # Stage 4 â€“ Pinecone Index
â”œâ”€â”€ streaming/
â”‚   â”œâ”€â”€ kafka_consumer.py             # Stage 2 â€“ Consumer
â”‚   â”œâ”€â”€ document_processor.py         # Stage 2 â€“ Streaming processor
â”‚   â””â”€â”€ vector_updater.py             # Stage 4 â€“ Index updater
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

---

## ğŸ”§ Usage

Ask regulatory queries via the Streamlit chat UI. Summaries update automatically in the sidebar.

**Example Queries**

* â€œSummarize RBIâ€™s master direction on digital lending.â€
* â€œFind details on Priority Sector Lending (PSL).â€
* â€œWhat are the main categories within PSL?â€

---

## ğŸ“¬ Connect

[LinkedIn â€“ Yashwanth Kasarabada](https://www.linkedin.com/in/yashwanth-kasarabada-ba4265258/)


